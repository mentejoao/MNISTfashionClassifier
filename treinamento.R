# Carregar as bibliotecas necessárias

install.packages("reticulate")
library(reticulate)
use_condaenv(condaenv = "C:\\Users\\dev06\\AppData\\Local\\anaconda3")
py_run_string("print('Hello from Anaconda Python')")

#install.packages("keras")
#install.packages("tensorflow")

#library(keras)
#library(tensorflow)

# Carregar os dados de treinamento e teste
mnist <- dataset_mnist()
train_images <- mnist$train$x / 255
test_images <- mnist$test$x / 255

train_labels <- to_categorical(mnist$train$y)
test_labels <- to_categorical(mnist$test$y)

# Criar a rede neural
modelo <- keras_model_sequential()

modelo %>%
  layer_flatten(input_shape = c(28, 28)) %>%
  layer_dense(units = 128, activation = "relu") %>%
  layer_dense(units = 10, activation = "softmax")

# Compilar o modelo
modelo %>% compile(
  optimizer = "adam",
  loss = "categorical_crossentropy",
  metrics = c("accuracy")
)

# Treinar o modelo e obter o histórico
history <- modelo %>% fit(
  train_images, train_labels,
  epochs = 10,
  batch_size = 128,
  validation_split = 0.2
)

# Imprimir resultados do treinamento por época
for (epoch in 1:10) {
  cat("Época", epoch, "\n")
  cat("   Perda de treinamento:", history$metrics$loss[[epoch]], "\n")
  cat("   Acurácia de treinamento:", history$metrics$acc[[epoch]], "\n")
  cat("   Perda de validação:", history$metrics$val_loss[[epoch]], "\n")
  cat("   Acurácia de validação:", history$metrics$val_acc[[epoch]], "\n")
}

# Avaliar o modelo
eval_result <- modelo %>% evaluate(test_images, test_labels)

formatted_accuracy <- sprintf("%.2f%%", eval_result * 100)
print(paste("Acurácia do modelo nos dados de teste:", formatted_accuracy))

# Substitua "caminho_para_salvar_modelo" pelo caminho onde você deseja salvar o arquivo do modelo
caminho_para_salvar_modelo <- "C:\\Users\\dev06\\Desktop\\tensorflow\\modelo.h5"
save_model_hdf5(modelo, caminho_para_salvar_modelo)
